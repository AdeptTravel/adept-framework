# Social Share System – Technical Specification

## 1. System Overview

The Social Share System is a distributed subsystem of the Adept platform responsible for **queuing and posting content to external social media platforms**.  Running alongside the Adept monolith on each node, it enables tenants to share content (initially articles) as text or video posts to channels including **YouTube, TikTok, X (Twitter), Facebook, Instagram, LinkedIn, BlueSky, Threads, and Google My Business**.  Each Adept node participates in a globally coordinated queue using CockroachDB for consistency, ensuring that posts are sent exactly once even in a multi-node deployment.  OAuth credentials for social platforms are stored per tenant or per user (never global or shared across tenants), so that each post uses the correct identity and permissions.  The system also integrates AI-assisted content generation: users can auto-generate suggested post text for an article via an AI helper button, then review or edit before queuing the post.

**Key capabilities include:** queuing posts (with optional scheduled times), reliably delivering them with retry on failure, and logging the outcome for tenant review.  Tenants interact with the Social Share System exclusively through its API endpoints (or UI interfaces that call those APIs) – never directly with the underlying database.  This isolation ensures that **only the Social Share service manipulates the global queue**, maintaining consistency and preventing tenant code from accidentally interfering with the queue.  Once a post is successfully delivered (or deemed permanently failed after retries), its record is migrated from the global pending queue into a tenant-specific table for historical reference and analytics.  Other components of Adept (for example, the Content component or form builder widget in the Admin UI) will integrate with this service to trigger sharing actions or display status, but they do so via defined interfaces rather than direct DB access.

## 2. Architecture and Component Responsibilities

The Social Share System consists of several cooperating components within the Adept monolith, each with clear responsibilities:

* **Social Share Service (Coordinator):** A singleton logical service (with an instance on each node) responsible for managing the share queue.  It provides API endpoints (or internal methods) that tenant-facing components call to enqueue a new share, query status, edit or cancel a scheduled share.  It encapsulates all business logic around validation of share requests (e.g. ensuring OAuth tokens exist, content is valid) and interacts with the database tables.  The service ensures that tenants can only see or modify their own share items, and all operations funnel through proper authorization checks.

* **Global Queue and Worker:** A background **worker routine** runs on each node to process the global share queue in a coordinated fashion.  All pending shares across all tenants reside in a global table (accessible cluster-wide) so that any node can claim and send an item.  The workers on different nodes communicate implicitly through the database – there is no direct inter-node communication, but **CockroachDB’s serializable transactions** provide consistency.  Each worker repeatedly looks for the next due share item that is not yet claimed, marks it as owned (to lock it), and then invokes the appropriate platform adapter to execute the share.  By using a **database-mediated locking mechanism** (detailed in the Locking section below), multiple nodes can safely work from the same queue without double-processing the same item.

* **Platform Adapters (Senders):** For each supported social platform, the system includes a dedicated **sender module** or adapter that knows how to format and deliver the post to that platform’s API.  These adapters handle platform-specific details such as authentication, API endpoints, payload formatting (e.g. video upload vs. text update), and error handling.  The Social Share Service will route each queued item to the correct adapter based on its `Platform` field (e.g. a YouTube share item is passed to the YouTube adapter).  To keep the system extensible, a common interface (e.g. `ShareProvider`) defines a method like `Post(content, credentials) error`.  Each platform adapter implements this interface, encapsulating differences (for example: YouTube requires a video upload and metadata; Twitter (X) has character limits and uses a text update endpoint; Instagram and Threads might require an image or video with the post; Google My Business posts may include a call-to-action link, etc.).  This design allows adding new platforms in the future by implementing the interface and registering the adapter, without changing core queue logic.

* **Credential Management:** OAuth tokens and credentials for social accounts are managed per tenant/user.  The Social Share System does not itself store raw credentials but relies on Adept’s credential storage and `internal/api` clients.  For instance, if a tenant’s administrator connects their Facebook account for sharing, that OAuth token is stored (likely encrypted, possibly in Vault or the database) in a tenant-scoped manner (e.g. in the global `oauth_identities` table or a similar secure store).  The share service, when processing a post, will retrieve the appropriate credential (based on the item’s tenant and possibly a user or account identifier) and use it to authenticate API calls.  No global credentials are used – **each share item explicitly references the tenant-specific or user-specific credential it needs**.  This ensures isolation: one tenant’s misconfigured token cannot affect others, and revoking a credential only impacts that tenant’s ability to share.

* **Integration Interface:** The Share System exposes its functionality via internal APIs or Go interfaces that other components can call.  For example, the Content Management component (which manages articles) may call `shareService.EnqueuePost(tenant, contentID, platforms, scheduleTime)` when an admin user clicks a “Share” button on an article.  In the Admin UI, a widget (possibly using the form builder infrastructure) might provide a form to customize a post message (and optionally trigger AI text generation).  That form then calls the share API to save the post to the queue.  By centralizing through the share service, we ensure consistent behavior (all shares go through the same validation and queue mechanism) regardless of which part of the UI or system initiated the share.

**Workflow Summary:** When a tenant user decides to share an article, the high-level flow is:

1. The user (through the UI) requests a share, providing target platform(s), optional custom message or using AI-generated text, and an optional scheduled time (or immediate send by default).
2. The request goes to the Social Share Service via an API endpoint (e.g. `POST /api/share`), including the tenant context and content reference.  The service verifies the request: it checks that the content exists and can be shared, ensures an OAuth credential is available for the chosen platform (erroring out with a clear message if not, e.g. “Facebook account not linked”), and assigns a unique ID.
3. The service writes a new entry into the **global share queue table**, representing the pending outgoing post.  This entry includes essential routing info (tenant, platform, scheduled send time, etc.) but not the full content payload (detailed payload is stored separately, see Database Schema below).  The service also creates or updates the **tenant’s share detail table** with the content of the post (text, video reference, etc.), initialization of attempt count, and a status of “queued”.  At this point, the post is accepted and will be sent out at the scheduled time.
4. A background worker on one of the nodes will pick up the task around the scheduled time.  The worker finds the queued item, claims ownership in the global queue, then reads the detailed content from the tenant’s share detail (or it may embed the content in the queue record – implementation can vary, but often the queue has a foreign key to detail).  Using the platform adapter, it attempts to post the content.  If the send occurs before a scheduled future time (because a user manually triggered immediate send), it effectively is handled as soon as possible.
5. Upon successful posting, the worker records the outcome: it removes the entry from the global queue (since it’s no longer pending), and updates the tenant’s detail record to mark it **completed** (status “done”) along with a timestamp and any returned post ID or URL (for reference).  If the platform returned a link to the new post or an ID, that is stored so the tenant can later see or click the social post from their dashboard.
6. If the posting fails, the adapter will return an error.  The worker marks a failure attempt in the detail record (increment the attempt count, capture the error message).  Depending on the failure type, it may **reschedule** the post: for transient errors (e.g. network issues or rate limit), the status remains “retrying” and a new `scheduled_time` is set based on an exponential backoff policy (the item stays in the global queue with the updated send time).  For permanent errors (e.g. invalid credentials or content rejected), the system marks the item as **failed**, removes it from the global queue, and records the final failure status in the tenant’s table (including the error reason for the user’s information).  In either case of failure, no other node will attempt the item while it’s owned or after removal – it will only be retried by the same mechanism via the updated queue entry if applicable.
7. Tenant users can query the status of their shares at any time via the service’s API (e.g. a UI might show a list of scheduled and recent shares).  The Social Share Service will gather this information by checking the global queue (for pending items) and the tenant table (for completed/failed items), and return statuses like “queued” (waiting in queue), “scheduled” (queued with a future send time), “in-flight” (currently being sent), “retrying”, “done”, or “failed”.  This gives real-time feedback in the UI.
8. If a user wishes to **edit or cancel** a pending share before it’s sent, they will invoke an edit/cancel action (through the UI to the service).  The Social Share Service handles this by removing or updating the item in the global queue (if it has not been sent yet) and updating the tenant detail record.  For edits, the pattern is to **remove the old queue entry and insert a new one** with updated content or schedule, rather than modifying in place (to simplify coordination logic).  The system ensures that at most one version of the item exists in the queue at a time.  (Details on how this is safely done are covered under Locking and Concurrency.)

This architecture ensures a clear separation of concerns: queuing and delivery logic is handled in the background by the share service, platform differences are isolated in adapters, and tenant-facing components simply enqueue requests and fetch statuses.  The design also supports horizontal scaling – multiple nodes can process shares in parallel – while maintaining consistency (each item is only sent once) via the CockroachDB-backed global queue.

## 3. Database Schema and Data Model

To support the queue and logging requirements, the Social Share System introduces **two tables**: a global queue table for pending items and a per-tenant table for share item details and history.  Splitting the data this way isolates security and access (tenants can only read their own detail records, not the global queue) and optimizes performance (the global queue is a centralized work list, while detail records can be partitioned by tenant).

**3.1 Global Queue Table (`social_share_queue`)** – This table lives in the *global* database (accessible to all nodes) and holds one entry per post that is scheduled or waiting to be sent.  It contains minimal information needed to pick and route the task.  Only the Social Share worker/service will read and write this table (no direct tenant queries).  Key fields proposed for this table include:

* `id` – **Primary key**.  A unique identifier for the queued share item (most likely a big serial or UUID).  This ID may also be used to link to the tenant detail record.
* `tenant_id` – The identifier of the tenant (site) that owns the share request.  This links to the global `site` table’s ID, so the worker knows which tenant context to load for credentials and content.
* `platform` – The target platform for the share (e.g. “youtube”, “facebook”, “twitter”, etc., possibly as a VARCHAR or an enum of supported platforms).
* `content_ref` – A reference to the content being shared.  This could be a foreign key or reference ID that, in combination with tenant context, allows retrieval of the content details.  For example, it might store the primary key of the tenant’s detail table record for this share.  Alternatively, it could hold a type and ID (if multiple content types) – but since initially only articles are shared, it may simply reference an article ID or a share detail ID.
* `scheduled_at` – Timestamp when the post is scheduled to be sent.  If the user wants an immediate send, this will be the enqueue time (essentially “now”).  If in the future, the worker will not send it until this time is reached.  The queue polling logic will filter for items whose `scheduled_at <= now()` to decide what can be sent.
* `status` – A status indicator for the queue item, such as “queued”, “in\_progress”, “retrying”, etc.  In many cases, the global queue may implicitly consider anything in it as queued or retrying until removed, so an explicit status field may be optional.  However, having a status can be useful (e.g. marking “in\_progress” when a worker has claimed it, which can aid in debugging and in preventing duplicate claims).
* `owner_node` – A field to support **distributed locking**.  This will hold the identifier of the node that has currently claimed the item for sending.  When no worker owns the item, this field is `NULL`.  When a worker picks it up, it sets this to its own node ID or name.  This serves as a lock so that no other node will attempt the same item.  (Details on usage in Section 4.)
* `owner_since` – A timestamp for when `owner_node` was set (when the item was claimed).  This can be used as part of a leasing mechanism: if a node crashes or stalls while owning an item, other nodes can detect an expired lease (no update after a certain duration) and release or reacquire the item.  (This field is future-proofing for failure recovery.)
* `created_at` – Timestamp when the item was enqueued.
* `updated_at` – Timestamp for last update (could be when status changed, etc.).

For clarity, here is a SQL DDL snippet proposing the **global queue table** structure (MySQL/PostgreSQL dialect for example purposes):

```sql
-- Global social share queue table (in global database/schema)
CREATE TABLE social_share_queue (
    id           BIGINT PRIMARY KEY AUTO_INCREMENT,   -- unique queue item ID
    tenant_id    BIGINT NOT NULL,                     -- references global.site(id)
    platform     VARCHAR(32) NOT NULL,                -- e.g. 'facebook', 'youtube'
    content_ref  BIGINT NOT NULL,                     -- references tenant share detail (ShareDetail.id)
    scheduled_at TIMESTAMP NOT NULL,                  -- time to send (now or future)
    status       VARCHAR(16) NOT NULL DEFAULT 'queued',  -- 'queued', 'in_progress', 'retrying'
    owner_node   VARCHAR(64) DEFAULT NULL,            -- which node owns the item for sending (null if none)
    owner_since  TIMESTAMP NULL,                      -- when ownership was taken
    created_at   TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at   TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    KEY idx_sched (scheduled_at),
    KEY idx_owner (owner_node, owner_since)
    -- (For CockroachDB, auto_increment may be replaced by unique_rowid() or similar.)
);
```

**3.2 Tenant Share Detail Table (`social_share_detail`)** – This table is created **per tenant** (most likely in each tenant’s schema or in a tenant-scoped database).  It stores the full details of each share item, including content, metadata, and history of attempts.  Only records relevant to a given tenant reside here, which means tenant users (through the share service API) can query their share history without risk of seeing other tenants’ data.  The Social Share Service writes to this table when a share is created and updates it as attempts are made or when completion/failure occurs.  Key fields for this table include:

* `id` – Primary key for the share record (unique within the tenant).  This can also serve as the `content_ref` stored in the global queue.  For uniqueness across the system, a composite of (tenant\_id, id) or a globally unique UID can be used.  Alternatively, the global queue could just store the tenant\_id and this id pair to identify the detail record.
* `content_type` – Type of content being shared: for now likely “article” or “text-post” vs “video”.  Initially only articles (with text snippet) are supported, but this field allows extension to other types (e.g. events, products, etc.) or differentiating pure text posts from video uploads.
* `content_id` – Reference to the actual content item in the tenant’s system if applicable (e.g. an article ID from the Content component).  This allows linking the share back to the original item (useful if we want to display, “Shared from Article: How to Cook Pasta” in the UI).
* `platform` – Redundant copy of the platform name (it’s also in the global queue).  Storing it here simplifies tenant queries (so they don’t need to join to global queue to know which platform a historical record was for).
* `post_text` – The text content of the post that will be shared.  This could be a user-written message or AI-generated suggestion combined with a link to the article.  It should support enough length to cover the longest platform (LinkedIn and Facebook can have lengthy posts, whereas Twitter is short – but we’ll store the full text and let the adapter trim or warn if needed).  If the post is a video upload, this text might be used as the description/caption.
* `media_path` – If a video or image is being shared, this field holds a reference to the media file.  For example, for a YouTube or TikTok share, this might be a path or identifier to a video file in the Adept media storage.  For an Instagram post, it could be an image path or video.  (Alternatively, the system might handle media differently, but including a field for it in the detail allows the share worker to know what file to upload.)
* `status` – The current status of the share item from the tenant perspective.  Possible values: “queued” (waiting to be sent), “scheduled” (queued with a future time), “sending” (currently in progress), “retrying”, “done” (sent successfully), “failed” (permanently failed).  This may mirror the global queue status while pending, and then final status once completed.  Having it here makes it easy to show status to the tenant via one table query.
* `attempt_count` – An integer count of how many send attempts have been made.  Starts at 0 on creation.  Each time a send is attempted (and fails), this increments.  Useful for implementing retry limits and showing history (e.g. “failed after 3 attempts”).
* `last_error` – A text or code field storing the error message of the last failed attempt (if any).  On success, this might be null or empty.  On a final failure, it contains the reason for failure (e.g. “Authentication expired” or API error details).  This helps admins debug why a share didn’t go through.
* `posted_url` – (Optional) The URL or identifier of the post on the social platform, if the post succeeded.  For example, after a successful Twitter post, we might store the tweet ID or URL; for YouTube, the video URL or ID.  This allows the UI to provide a direct link (“View on Platform”) for convenience.  If the platform API returns an ID, we can construct a URL if needed.
* `scheduled_at` – The scheduled send time (copied from the queue at creation for reference).  If immediate, this will equal the creation time.  If rescheduled due to retries, this field might be updated to the next send time, or we might keep the original request time here and rely on the global queue for next attempt time.  (We could also maintain a separate `next_attempt_at` if needed to track the latest schedule after retries.)
* `created_at` – Timestamp when the share was originally created (enqueued).
* `sent_at` – Timestamp when the share was actually sent (set when status transitions to done).  If failed, this might remain null or set to the final attempt time.
* `completed_at` – Timestamp when the share processing completed (either successfully sent or permanently failed).  This could be the same as `sent_at` for success, or time of final failure for a fail case.

A sample **tenant share detail table** definition:

```sql
-- Per-tenant social share detail table (each tenant schema)
CREATE TABLE social_share_detail (
    id             BIGINT PRIMARY KEY AUTO_INCREMENT,   -- share record ID (unique per tenant)
    content_type   VARCHAR(32) NOT NULL DEFAULT 'article',
    content_id     BIGINT NULL,                         -- reference to internal content (e.g. article ID)
    platform       VARCHAR(32) NOT NULL,
    post_text      TEXT NOT NULL,                       -- content of the post (text)
    media_path     VARCHAR(255) DEFAULT NULL,           -- optional path/ID for video or image
    status         VARCHAR(16) NOT NULL DEFAULT 'queued',
    attempt_count  INT NOT NULL DEFAULT 0,
    last_error     TEXT DEFAULT NULL,
    posted_url     VARCHAR(512) DEFAULT NULL,           -- URL or external ID of the post (on success)
    scheduled_at   TIMESTAMP NOT NULL,                  -- when send is/was scheduled
    created_at     TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    sent_at        TIMESTAMP NULL,
    completed_at   TIMESTAMP NULL,
    INDEX idx_status (status),
    INDEX idx_sched (scheduled_at)
    -- Note: a foreign key to global.social_share_queue could be added if we want referential integrity
    -- for example, content might be in queue until done. But since on completion we remove from queue,
    -- a direct FK might not be permanent. Instead, store queue id in this table if needed for linking.
);
```

In terms of **Go data structures**, the key models can be represented with struct definitions.  We expect something like:

```go
// internal/share/model.go
//
// Social Share data models: defines the structures for queue items and share details.
// These mirror the database schema for easy serialization via sqlx or ORM.
//
// Fields overview:
// ----------------
// • ShareQueueItem – Represents a pending share in the global queue (minimal info).
// • ShareDetail    – Represents the full share record in a tenant's scope (content and history).
//
// Both structures include JSON and DB tags for integration with the database layer.
type ShareQueueItem struct {
    ID          int64     `db:"id"`           // unique queue identifier (global scope)
    TenantID    int64     `db:"tenant_id"`    // owning tenant ID (references site.id)
    Platform    string    `db:"platform"`     // target platform name
    ContentRef  int64     `db:"content_ref"`  // reference to ShareDetail.id in tenant DB
    ScheduledAt time.Time `db:"scheduled_at"` // when to send
    Status      string    `db:"status"`       // e.g. "queued", "in_progress", "retrying"
    OwnerNode   string    `db:"owner_node"`   // node that has claimed this item (empty if none)
    OwnerSince  time.Time `db:"owner_since"`  // timestamp when OwnerNode was set
    CreatedAt   time.Time `db:"created_at"`
    UpdatedAt   time.Time `db:"updated_at"`
}

// ShareDetail holds the detailed info about a social share (tenant-scoped).
type ShareDetail struct {
    ID           int64     `db:"id"`            // share record ID (tenant scope)
    ContentType  string    `db:"content_type"`  // e.g. "article"
    ContentID    *int64    `db:"content_id"`    // pointer used because it can be null
    Platform     string    `db:"platform"`
    PostText     string    `db:"post_text"`
    MediaPath    *string   `db:"media_path"`    // optional media reference
    Status       string    `db:"status"`        // "queued", "scheduled", "sending", "done", "failed"
    AttemptCount int       `db:"attempt_count"`
    LastError    *string   `db:"last_error"`
    PostedURL    *string   `db:"posted_url"`
    ScheduledAt  time.Time `db:"scheduled_at"`
    CreatedAt    time.Time `db:"created_at"`
    SentAt       *time.Time `db:"sent_at"`
    CompletedAt  *time.Time `db:"completed_at"`
}
```

*Comment:* In the Go structs above, pointer types (like `*int64` for `ContentID`) are used for optional fields to distinguish zero values from null.  The `db` struct tags indicate how fields map to DB columns.  The structures would likely have accompanying methods or functions to translate between the global queue item and tenant detail (for example, when a worker pulls a ShareQueueItem, it uses `TenantID` to connect to the tenant’s database and load the corresponding `ShareDetail` by `ContentRef`).  Additionally, not every field needs to be duplicated across tables – some fields (like `Platform` and `ScheduledAt`) may appear in both places for convenience.  Developers should keep those in sync (the service will copy values from the request into both records at creation).

## 4. Locking and Ownership Coordination

To **safely coordinate** multiple worker processes across distributed nodes, the Social Share System employs an explicit locking and ownership mechanism at the database row level.  The goals are to ensure that **each share item is processed by at most one node** and to prevent race conditions where an item might be sent while a user is editing or rescheduling it.

**Ownership Field:** The global queue table contains an `owner_node` column (and `owner_since` timestamp) as described.  This is used to implement a **leader-election per item**.  The process works as follows:

* When a worker is ready to send the next item, it performs a query on `social_share_queue` for the oldest or highest-priority item that is due (`scheduled_at <= now()`) and is not already owned.  For example, a SQL query might look for `WHERE owner_node IS NULL AND status = 'queued' AND scheduled_at <= now() ORDER BY scheduled_at ASC LIMIT 1` for the next candidate.

* To claim the item, the worker uses an atomic update: it will attempt to set `owner_node` to its own identifier and change status to “in\_progress”.  This can be done in a single SQL statement like:

  ```sql
  UPDATE social_share_queue 
  SET owner_node = '<node-id>', owner_since = NOW(), status = 'in_progress'
  WHERE id = <ID> AND owner_node IS NULL AND status = 'queued';
  ```

  Because the `WHERE` clause requires `owner_node IS NULL` (and optionally status is still 'queued'), this update will succeed only if no other worker has claimed the item in the interim.  If the update’s affected-rows count is 1, the worker knows it now owns that item.  Other nodes attempting the same for that item would find the `owner_node` no longer NULL and thus their update yields 0 rows, meaning they failed to claim – so they’ll skip that item.  This leverages the **optimistic locking** approach using the DB as the lock coordinator.

* Once a worker has set itself as owner, it proceeds to process the item (load details, send to platform).  Other workers will not touch this item now, because it’s marked with an owner.  Even if another worker scans the queue and sees this item, it will skip it due to the non-null owner or status “in\_progress”.

* After processing (success or final failure), the worker will remove the item from the global queue (DELETE it) or mark it as completed.  At that point, it’s gone from the pending list, freeing any lock implicitly.  If the item needs to be retried, the worker might update fields like `status = 'retrying'` and set a new `scheduled_at` in the future and **clear the owner\_node** (to release it back to the queue for later reprocessing).  It’s important that the worker clear its ownership (and status) when deferring an item; otherwise it would remain locked indefinitely.  One strategy is: on a transient failure, perform an UPDATE such as `owner_node = NULL, status = 'queued', scheduled_at = <new time>` so that the item is effectively re-queued for the future, available to any worker when the time comes.

* The `owner_since` timestamp can be used to detect stuck items.  For instance, if an item has been in `in_progress` with the same owner for a very long time (longer than any expected posting operation, say > 15 minutes or an hour), it might indicate the worker crashed or failed to release.  A monitoring or recovery routine could periodically scan for such cases and clear the owner if needed (perhaps also limiting to items that haven’t seen an `updated_at` change in a long time).  This ensures robustness: one node failure won’t permanently stall an item.  CockroachDB’s **consensus replication** means that even if one node goes down, the remaining nodes still see the database and can perform these checks.

**User Edit Locking:** The system must also avoid the scenario where a user edits or cancels a queued post at the same time as a worker is sending it.  We handle this by coordinating the removal/update operations with the same ownership field:

* If a user requests to cancel or edit a scheduled post, the Social Share Service will attempt to remove it from the global queue (and detail table).  However, it should only do so if the item is not currently being processed.  To enforce this, the deletion or update query for an edit will include a condition that `owner_node IS NULL` (and perhaps `status = 'queued'` or `'retrying'`).  For example:

  ```sql
  DELETE FROM social_share_queue 
  WHERE id = <ID> AND tenant_id = <TID> AND owner_node IS NULL;
  ```

  This ensures that if a worker has already claimed the item (owner\_node set), the deletion will not happen (0 rows deleted).  In that case, the service would know the item is actively being sent and cannot be edited or canceled.  It can then inform the user (e.g. return an error or a status like “already in progress, unable to edit”).  This prevents the race where a post is being sent out while the user thinks it’s canceled or changed.

* In the more likely scenario (the user is editing an item well before its scheduled send time), `owner_node` will be NULL, so the deletion succeeds, effectively **removing the item from the pending queue**.  The service can then safely create a new queue entry if the user saved changes (this new entry will have updated content or time).  This remove-then-add approach guarantees that there’s never two active entries for the same intended post, and the edit operation is atomic from the user’s perspective.

* We considered adding a separate explicit `locked` flag to indicate a user is editing the item (to prevent the worker from sending it during a long edit window).  However, in practice the edit operation occurs as a quick transaction (the user submits changes or cancel at a point in time).  We are not holding an open lock while the user is typing; instead, we simply ensure the item is removed or marked before it can be sent.  The user interface will typically disable editing for items that are already sending or sent.  Therefore, the combination of checking `owner_node` and status is sufficient.  For additional safety, we could implement a short-lived “edit lock” by setting a flag when the edit form is opened and clearing it on cancel/submit, but this adds complexity.  The simpler rule stands: **no edits allowed if the item is currently owned by a worker or already done**.

**Transaction Management:** Both the worker’s claim operation and the user’s removal/edit operations happen within transactions (implicitly or explicitly).  CockroachDB’s serializable isolation ensures that concurrent transactions will be resolved without corrupting data.  For example, if a user tries to delete an item at the exact moment a worker is claiming it, one of the operations will win based on transaction commit order – either the worker’s update sets the owner (and then the delete finds no match, as intended), or the delete happens first (removing the item so the worker’s update finds no row).  Either outcome is safe.  We carefully structure the SQL conditions as described so that no partial updates leave the system in an inconsistent state.

**Ownership Granularity:** The `owner_node` approach currently locks one item at a time.  This is sufficient given each item is independent.  In the future, if performance tuning is needed, we could consider claiming batches of items or using separate queue partitions per node.  However, CockroachDB can handle a high rate of row updates, and each share item is fairly weighty (posting a video, etc.), so processing will not be extremely high QPS such that DB locking becomes a bottleneck.  Still, we include the `owner_node` field in the schema from day one to accommodate multi-node from the start, and to allow possible enhancements like node affinity (e.g. an “ownership” concept where certain tenants’ tasks might preferentially be handled by specific nodes, though initially all workers are equal).

## 5. Platform-Specific Send Logic

Each target social platform has unique APIs and requirements.  The Social Share System is designed with a **pluggable provider architecture** (similar in spirit to Adept’s messaging providers, but specialized for social media).  The send logic for a platform will typically involve the following steps: OAuth authentication, content formatting (text, media, links), API call to create the post, and interpreting the response to determine success or failure.

**Adapter Interface:** We define an interface (e.g. `type ShareProvider interface`) with methods such as `Post(ctx, detail *ShareDetail, cred Credential) error`.  Each platform implements this.  The Social Share Service or worker does not need to know details of how, say, LinkedIn’s API differs from TikTok’s – it just calls the provider.  This clean separation means we can update one provider (if an API changes) without affecting others, and we can conditionally enable/disable certain platforms based on configuration.

**Per-Platform Considerations:**

* **Facebook:** Will use the Facebook Graph API.  Likely supports posting to pages or profiles.  For text posts with a link (like an article share), the adapter might call the `/me/feed` or a page feed edge with a message and link.  OAuth token scopes must include publish permissions.  Our adapter will ensure the message text from `ShareDetail.PostText` is included, and if an article URL is to be shared, it will append or include it (the user interface could automatically include the article link in `PostText`, or the adapter could append it if not present).  Facebook might return a post ID which we’ll store as `posted_url` (we can construct a direct link like `facebook.com/<userOrPage>/posts/<id>`).

* **X (Twitter):** Uses the Twitter API (v2 or v1.1 depending on availability for posting tweets).  Twitter has a character limit (e.g. 280 chars).  The adapter should truncate or warn if `PostText` exceeds this.  If media (image/video) is included, Twitter requires a separate upload step (e.g. POST media/upload to get a media\_id, then POST statuses/update with that media\_id and text).  Our design supports video, but realistically, Twitter allows short videos – we will handle this through the media path if provided (upload via API and attach).  The adapter must use the user’s OAuth token (with write permissions) and handle any specifics like @mentions or hashtags in text (no special handling needed beyond ensuring they’re not stripped by encoding).  The response will include a Tweet ID; we store a URL like `https://twitter.com/user/status/<id>`.

* **Instagram:** Instagram’s API (for posting) is typically available via the Facebook Graph API for Business accounts, or not directly for personal accounts.  Likely we will support Instagram Business accounts posting (which require an image or video and a caption).  The adapter will need an image or video – if `media_path` is provided, we use it; if not (and only text), we might not allow a text-only Instagram post (could flag as error).  The workflow might involve uploading the media and then creating a Media Publish.  This is a bit complex (Instagram Graph API requires publishing container creation, etc.), so this adapter might be more involved.  We’d ensure to store if media was required and not present (error out accordingly).  On success, no easily accessible URL (since personal posts don’t have API to get link easily), but for business accounts, we might get an ID.

* **LinkedIn:** LinkedIn’s API allows sharing posts on a user or organization’s behalf.  Typically, one can share text and link, and images.  For videos, LinkedIn has an upload API as well.  The adapter will call the `/ugcPosts` endpoint (for user-generated content) or a simpler share endpoint.  It needs the OAuth token of the user (with correct scope like `w_member_social`).  It will include `PostText` as the content of the post; if an article link is present, LinkedIn can attach a preview automatically if the link is included in the request payload.  We might differentiate if the content is just text vs link share.  On success, LinkedIn returns an update URN which we can transform or store.

* **YouTube:** YouTube integration focuses on video uploads.  The share system can take a video file from `media_path` (which might be a path on disk or cloud storage accessible to the server) and upload it to the tenant’s YouTube channel.  The adapter will use the YouTube Data API.  This likely involves a resumable upload: our worker might have to use Google’s client library or a direct HTTP upload to send the video file.  We would supply metadata: title and description.  For title, we might use the original article’s title or allow the user to specify a separate title (the spec doesn’t detail this, but we can use `PostText` for description and perhaps take the first line or a special field for title).  OAuth credentials: YouTube requires OAuth 2.0 with the appropriate scope (e.g. `youtube.upload`).  The `posted_url` stored would be the YouTube video link.  Because video uploads can be time-consuming, our worker must handle this carefully, possibly updating progress (though in initial version we might just treat it as one long transaction).  Retries for video should be careful – if a video partially uploaded, we might need to abandon or get a new upload URL.

* **TikTok:** TikTok provides an API for uploading videos (and possibly caption text).  Similar to YouTube, our adapter will handle reading the video file and uploading it.  TikTok’s API might require requesting an upload URL, then PUTting the file, then committing the post with a caption.  We’ll use `PostText` as the caption.  Credential-wise, TikTok tokens may expire quickly, so we will ensure refresh tokens if available or handle auth errors as retryable (maybe prompting re-login out-of-band if needed).  The result could give a video ID or link for `posted_url`.

* **BlueSky:** BlueSky uses the AT Protocol (decentralized).  There may not be OAuth tokens in the traditional sense; it might use app passwords or did\:plc identifiers.  For our purposes, if BlueSky integration is desired, we might have to use the ATProto client.  The adapter would take `PostText` (BlueSky posts are text limited similar to tweets, maybe 300 chars) and call the appropriate API (like `bsky.feed.post`).  If an image is included, attach via blob upload.  BlueSky is evolving; our design just ensures we can plug in such an adapter when the API and demand are clear.  We’d store the post’s URI or an identifier on success.

* **Threads:** Threads (by Meta) does not yet have an official API (as of the initial design), but anticipating one, it would likely resemble a mix of Instagram and Twitter.  We’ll plan for an adapter that posts text (and optional media) via whatever endpoint Meta provides.  It might require an Instagram OAuth token since Threads is tied to Instagram accounts.  For now, this remains a placeholder – the system’s architecture is flexible to add it when available.

* **Google My Business (Google Business Profile):** Posting here means creating an update on a Google Business Profile (like an offer or event).  The adapter will use Google’s My Business API.  The content might include text, media, and call-to-action link.  We may map an article share to a GMB post by using the article URL as the call-to-action link and a snippet of text as the post.  The OAuth credential is typically the Google account that manages the business listing, which the tenant would have connected.  After posting, Google returns an ID for the local post; we can’t directly get a public URL to the post (since it appears on Google’s search/Maps interface), but we store the post ID or name for record.

Across all these adapters, a few common patterns emerge: use the tenant/user-specific OAuth token, handle content formatting, call the external API, and interpret the response or error.  We will likely implement each adapter in its own Go file or sub-package (e.g. `internal/share/provider/facebook.go`, `twitter.go`, etc.) with clear naming.  The Social Share Service will maintain a registry or map of platform name to adapter instance.  When a new share item comes in, if the platform isn’t supported or not configured, the service will reject it early with a clear error (“Platform X is not supported” or “Account for Platform Y not connected”).

**Error Handling and Retries:** Each adapter should classify errors into **retryable** vs. **non-retryable**.  For example, a network timeout or 503 from the platform API is retryable (the service will try again after a delay), whereas an error like “invalid access token” or “permission denied” is likely not retryable without user intervention (the system will mark the share as failed and include the error, so the tenant knows they may need to re-authenticate or check account permissions).  The adapters can return a special error type or code to indicate this (or simply the worker can have logic: certain HTTP status codes map to permanent failure).  The **retry back-off** strategy might be: first retry after 5 minutes, then 15, then 30, then 1 hour, etc., up to a maximum number of attempts (configurable, perhaps default 3 or 5).  These retries are scheduled by updating `scheduled_at` in the global queue.  Each attempt’s timestamp and result should be recorded in the detail (increment attempt count and update last\_error).

**Posting Concurrency:** While multiple different items can be processed in parallel by multiple nodes, we might also limit concurrency per platform or per tenant to avoid hitting rate limits.  For instance, Twitter’s API might not appreciate 10 posts in the same second from one account.  A simple approach is to have the worker loop fetch one item at a time; given the likely volume (not extremely high frequency), this may be sufficient.  If needed, we can implement per-tenant or per-platform throttling (e.g. using an in-memory rate limiter or checking timestamps of last post per account).  This is a potential future enhancement if high volume usage is expected.

In summary, the platform-specific logic is encapsulated, but the Social Share System will be configured to handle text and video posts appropriately for each channel.  Comprehensive testing for each adapter is necessary, as these third-party APIs can be finicky.  The system should log detailed information during each send attempt (for debugging) but avoid logging sensitive data (like OAuth tokens or personal info).

## 6. Integration Points with Other Components

The Social Share System is not an island; it works in concert with various parts of the Adept platform.  Key integration points include:

* **Content Management Component:** Initially, only content articles can be shared via this system.  The Content component (which handles creating and editing articles/pages) will likely provide the UI trigger to share an article.  For example, in the admin interface for an article, there may be a “Share” button or tab.  When clicked, it could open a “Share this Article” dialog where the user selects platforms, writes an optional message, and chooses immediate or scheduled posting.  Under the hood, that dialog will call the Social Share API (possibly an endpoint like `/api/share/article` with the article ID, platform, message, etc.).  The share system might also integrate with the Content component to retrieve article metadata – e.g., an article’s title or URL might be needed to include in the post.  Therefore, the share service might call a Content API to get the canonical URL of the article and automatically include it in the share payload (unless the user manually edits it out).  Additionally, when an article is successfully shared, the Content component could be notified or at least able to show that status (for instance, a list of past shares on that article).

* **AI Text Generator (AI Integration):** As noted, the system supports AI-assisted post generation.  This likely uses Adept’s AI subsystem (internal/ai with an OpenAI or other provider).  The integration could work like this: In the share UI, there’s a button “Generate Suggestion” which, when clicked, sends the article content (or summary) to an AI service to get a suggested social post text (maybe with a creative tagline or relevant hashtags).  This could call an internal endpoint like `/api/ai/generatePost` or reuse the AI component functions.  The result is then shown in the UI for the user to edit or accept.  This process doesn’t directly involve the queue, but it’s a user-facing enhancement that relies on Adept’s AI integration.  We must ensure this generator is tenant-scoped (uses the tenant’s configured AI API keys if applicable) and that it follows any length/style guidelines for the platform.  The share system spec includes it to highlight that generating content is part of the workflow, even if the actual generation logic lives in the AI component.  The Social Share System might simply provide a convenient hook or pass-through to the AI layer (for example, a method in the share service: `GeneratePostSuggestion(articleID) -> string` which internally calls the AI helper with the article’s title and a brief summary).

* **Forms and Admin UI Widgets:** In the future Admin UI (likely a web interface for tenants to manage content and settings), the Social Share System will present forms or widgets for scheduling posts.  This could leverage the Adept form builder subsystem (for example, a pre-defined form for “New Social Post” that includes fields for message, platform selection, date/time picker for scheduling, etc.).  Using a form definition has the advantage of consistency and validation (e.g., we could enforce maximum length in the form, or require that either text or media is provided depending on platform).  The mention of a *form builder widget* suggests that perhaps the share UI might be composed as a form widget that can be embedded in admin pages.  Integration here means the share service might define a widget or component that the Admin UI can call, or at minimum, expose endpoints that a form submission triggers.  For example, an HTMX or Vue-based admin panel could have a component that interacts with the share service’s REST API.

* **Security & Permissions:** Only authorized users should be able to initiate shares.  Likely, Adept’s role-based access control (RBAC) will integrate here.  The share service should check that the user has a role that permits social posting (maybe an “editor” or “social\_media\_manager” role).  The `user_role` table ties global users to roles per tenant.  So when an API call comes in to create a share, the share service (which is part of the monolith) can use the already established session user context to verify permissions.  Integration with the Auth component is indirect but important: ensure that the endpoints require login and proper role.  The system could also log which user initiated a share (perhaps in the tenant detail record or an audit log) for traceability.

* **Credential Store (Vault/Config):** As discussed in Platform Logic, the share service needs to fetch OAuth tokens.  Adept’s configuration and secret management (Vault integration) is used for API keys.  However, user OAuth tokens (like “token to post to Twitter on behalf of user X”) might be stored in Adept’s database (for instance, the `oauth_identities` table could be extended to include providers like Twitter, Facebook, etc.).  If so, integration means that when a user connects their social account via the UI, that process goes through Auth/OAuth logic and ends up populating credentials in the DB (or Vault).  The Social Share Service then looks up the token in `oauth_identities` (or similar) matching the user and provider when it needs to post.  It’s crucial that the share system never sees the user’s raw credentials in plaintext – likely these tokens are stored encrypted (the example schema has `access_token_enc`).  We would use a Vault-stored key to decrypt at runtime (Adept likely has a Vault client for such).  This integration ensures security of credentials while still allowing the automated system to act on behalf of the user or tenant.

* **Messaging/Notification** (Future): While not in initial scope, the share system could integrate with the broader messaging subsystem.  For example, if a share fails permanently, we might want to notify the tenant admin via email or an in-app notification.  Or if a post is successfully published, maybe a confirmation notification.  This would leverage Adept’s internal messaging queue (once that exists).  This is noted as a future possibility – the initial design will likely suffice with the UI polling or showing status.

* **Analytics and Observability:** Integration with Adept’s observability means emitting metrics for Prometheus and logs for analysis.  For instance, each platform adapter could increment counters like `adept_share_posts_total{platform="twitter", status="success"}` or `adept_share_posts_failed_total{platform="facebook"}` to allow dashboards of how many posts have been sent and how many failed.  These metrics integrate with the existing Prometheus setup in `internal/observability`.  Likewise, any errors or major events should be logged (structured logs) so that operators can troubleshoot issues (for example, log an error with fields: tenant, platform, error type, etc.).  Tracing (OpenTelemetry) could be integrated to trace a share request from the API call through to the external API call, which is useful in a distributed system for performance monitoring.

In essence, the Social Share System touches many parts of Adept – content management, user auth, external APIs, and admin UI.  We design it to **encapsulate the complexity** (so other components don’t need to know the details of queueing or platform APIs) yet provide clear hooks for those components to use (like simple API calls and callback points).  This modular approach follows Adept’s architecture principles of separation of concerns and reusability.

## 7. Concurrency Safeguards and Race Conditions

Beyond the locking mechanics discussed, there are several concurrency scenarios that the Social Share System handles explicitly to maintain correctness:

* **Double Sending Prevention:** The combination of the global queue and owner lock is our primary guard against double sends.  If two nodes somehow attempt to send the same item, only one will succeed in setting the owner and proceeding.  The other will find it locked and move to the next item.  Additionally, once an item is sent and removed from the queue, any stray attempt (due to a rare race or bug) will not find the item to send.  We ensure that the deletion of the queue entry and updating the tenant record happen together (in the worker’s success path) so that there’s no window where another process thinks it’s still pending.  CockroachDB’s transactional consistency means even across node restarts, the state will be correct (either the item is there or it’s gone, no half-state).

* **Idempotent Processing:** It’s worth designing the send operations to be **idempotent** where possible.  For example, if a worker crashes right after successfully posting to a platform but before it deletes the queue entry, what happens?  The item might still be in the queue when the system recovers, and could be retried by another worker.  This could result in a duplicate post on the social platform.  To mitigate this, we consider marking an item as completed before actually making the API call – but that’s not possible because we only know success after the call.  Instead, we rely on external safeguards: e.g., many social APIs have an idempotency key or de-duplication for immediate retries, but that might not cover our scenario.  **Our approach**: if a crash occurs, the item will still be marked `owner_node` by the crashed node and will not be picked up until we detect and clear the stale lock (using `owner_since`).  We can set a relatively short threshold for “stale in-progress” (maybe a few minutes more than typical posting time).  This reduces the chance of rapid duplicate processing.  Furthermore, when we do eventually retry such an item, we could include logic in adapters to check if the content might have been posted already (if possible, e.g. by searching recent posts via API).  This is complex, so initially we accept a small risk of duplicates in extreme failure cases, but document it and possibly alert operators to manually check if needed.  In normal operation, the design avoids double-send effectively.

* **Edit vs Send Race:** As described, if a user submits an edit just as the item is sending, our conditional deletion prevents removal if `owner_node` is set.  From the user perspective, they might hit “save changes” and get an error “Post already in progress or sent; changes not applied.”  This is a reasonable outcome in that edge case.  They may then see the post was already sent (or will be momentarily).  It’s better than silently having either an old version sent or a post canceled at the last millisecond.  If this becomes a frequent issue (perhaps users scheduling very close and trying to edit last-minute), a possible future improvement is to implement an “editing lock”: e.g., if an item is scheduled for 1 hour later and a user starts editing it, we could temporarily set a flag so the worker will skip it even if the time comes, until the user either finishes editing or a short grace period passes.  However, such complexity is deferred unless a real need arises; our simpler approach is deemed sufficient for expected usage patterns.

* **Multiple Platform Posts from One Request:** If in the future we allow one user action to share an article to multiple platforms at once (e.g. “Share this to Facebook, Twitter, and LinkedIn”), how do we handle that?  The design could either create separate queue entries for each platform (preferred for clarity and isolation of failures), or a single queue entry that triggers multiple sends.  We lean towards **separate entries** per platform, even if triggered by one form submission.  That means if a user selected three platforms, the system will create three records (and perhaps group them under the hood with a common batch ID or simply by having same content and time).  Each will be processed independently.  This avoids one platform’s failure affecting the others – e.g. if Twitter fails but Facebook succeeds, they should be tracked separately.  The UI can present them as one combined “campaign” or simply list them individually.  Concurrency-wise, those could even be sent in parallel by different nodes.  If the platforms need to be somewhat synchronized (not usually), we could schedule them at roughly the same time.  This doesn’t pose a race condition per se, but it’s a design choice that influences how we log and coordinate multi-platform shares.  We note it here as the system should be prepared to handle simultaneous multiple entries created at once.

* **Database Transaction Contention:** With CockroachDB and possibly high throughput, we should consider if the queue table could become a hotspot.  The use of an index on `scheduled_at` and selecting one item at a time is efficient, but if many items become due at exactly the same time, multiple nodes might contend on adjacent rows.  CockroachDB can handle this by distributing ranges by primary key.  Since our primary key is an increasing ID, new inserts go to the end of the table – which might all be on one range.  However, selecting by `scheduled_at` could scan a portion.  We might mitigate hotspots by introducing a pseudo-random component or by sharding the queue table by tenant or by some hash.  For now, given moderate expected load, a single table is fine.  We acknowledge that in very high scale scenarios, a different approach (like using a built-in job scheduler or message queue) might be preferable.  This is mentioned as a future path (e.g. evaluating a queue engine or separating the queue out of the SQL DB).  The current design favors simplicity and consistency within the existing stack.

* **Clock Synchronization:** Since scheduling relies on `scheduled_at` timestamps, it’s important that all nodes have reasonably synchronized clocks (within a small skew).  CockroachDB uses NTP and logical time for transactions, so it should be consistent cluster-wide.  We should ensure that if a user schedules for a specific time, the system does not send significantly earlier or later due to clock issues.  Typically, we’ll trust the DB server time.  If needed, we could add a slight delay tolerance (for example, only send if `scheduled_at <= now() - 2 seconds` to avoid borderline cases).  This is a minor safeguard.

* **Thread Safety in Code:** Within a single node, the share worker might spawn multiple goroutines for parallel sends (especially if we want to handle multiple items concurrently on one node).  Access to any shared resources (like a common in-memory cache of credentials or rate limiter) should be synchronized.  Our design mostly avoids shared state by isolating each send.  If using any global maps (like platform adapter registry or a cache of recently used tokens), we will use proper locking or concurrent-safe structures.  The Go context can be used to cancel operations if the server is shutting down (the worker loop will listen for context cancel on shutdown to stop gracefully, finishing any in-progress sends before exit).

In summary, the concurrency safeguards revolve around *preventing simultaneous conflicting actions* and *ensuring recovery from partial failures*.  By leveraging the database for distributed locking and by writing our operations to be conditional, we cover the main race conditions (edit vs send, multi-node duplication).  The design assumes relatively low concurrency on the exact same item (which is reasonable – multiple users wouldn’t typically edit the same post simultaneously, and one item can only be sent once).  The heavier concurrency is across different items, which the system is built to handle in parallel.  We will thoroughly test scenarios like rapid-fire scheduling, node failures mid-send, and edit-while-sending to validate these safeguards.

## 8. Future Enhancements and Considerations

While the above specification covers the MVP of the Social Share System, several extensions and improvements are anticipated as the platform grows:

* **Additional Content Types:** Initially only articles are shareable, but the system is built to be extensible.  In the future, other components (e.g. an Events component or an E-commerce component for products) may leverage the share queue to post updates.  To accommodate this, the `content_type` and `content_id` fields in the detail table allow identifying what is being shared.  We might generalize some of the logic so that, for example, if a product is launched, a marketing team can share a product page link to social media through the same mechanism.  The share service could expose a more generic API (not just “share article” but “share content”, with perhaps a content type and reference).  We’d ensure any component-specific differences (like formatting the text differently for an event vs an article) could be handled either by that component preparing the `PostText` or by the share service having templates per type.

* **User Interface & Scheduling UX:** As we develop the Admin UI, the social share interface can be improved with calendars or content calendars, preview of scheduled posts, etc.  The system supports scheduled times and status queries already.  A potential enhancement is a **calendar view** of scheduled outgoing posts, or integration with third-party social media management tools (exporting a calendar feed, for instance).  We may also implement draft posts that are not queued until approved – currently, once a post is queued it will send at scheduled time unless edited; adding a “draft” concept could let teams collaborate on social posts before scheduling them.

* **Enhanced Logging and Audit Trails:** We log basic attempt info now, but we might want a more detailed audit.  For example, keeping a **history of all attempts** (not just last error) in a normalized way.  This could mean a child table like `social_share_attempt` recording each try with timestamp, error code, etc.  We chose not to implement that initially to keep it simple, but as the system matures, having that data could help in analyzing delivery issues or proving to clients “we attempted this 3 times, here are the error responses”.  Another related enhancement: capturing the actual content that was posted (in case the original content changes later, we have a record of what exactly was sent).  Currently, `post_text` is stored, which suffices, but if images/videos are external, maybe store a copy or ensure the path remains valid.

* **Integration with External Schedulers/Queues:** If the volume of social posts increases significantly or if we face performance issues with the DB-based queue, we might integrate a message broker or queue engine.  For example, using NATS JetStream or Apache Kafka for distributing jobs could offload the contention from the SQL database.  We would then transform the Social Share Service to enqueue messages to that broker and have workers subscribe.  CockroachDB would still likely be used for persistent logging (the tenant detail records for history), but the global coordination could shift to an external system.  This is a non-trivial change and would be considered if scaling demands it (as indicated in the roadmap research about queue engines).  Our current design with an `owner_node` and Cockroach is sufficient for MVP and medium scale.

* **Post Content Enhancements:** We could add features like automatically shortening URLs (for Twitter, if needed, although Twitter now auto-shortens links), or automatically adding UTM parameters to links for analytics tracking when posting to social.  The share service could interface with a URL shortener or just ensure that if a link is present, it’s properly encoded.

* **Platform Webhook Integration:** Some platforms offer webhooks or callbacks (e.g. to notify when a post is published, or if a post was deleted, or to get engagement metrics).  In future, we might integrate these to enrich our system.  For instance, after posting, we could receive data about how many likes or views a post got, and display that in Adept’s dashboard.  Or for YouTube, getting a confirmation that processing is done (since YouTube video upload might initially be “processing”).  This would likely involve adding endpoints in Adept to receive these callbacks and update records.  It’s beyond MVP but aligns with offering a fuller social management suite.

* **Multi-Tenancy and Agency Features:** If an agency manages multiple tenants, or if one tenant has multiple sub-brands, we might consider features like cross-posting the same content to multiple tenant accounts (not likely common, but possible if say a chain of sites want to share a corporate announcement).  Our design doesn’t explicitly cover cross-tenant sharing (each queue item is tied to one tenant and one account).  If needed, we could support a parent-child relationship or a way to duplicate a share across tenants easily (more of a tooling convenience than core system change).

* **Error Handling Improvements:** Provide more actionable feedback for failures.  For example, if a token is expired, the system could automatically attempt a token refresh (if refresh token available) rather than immediately failing.  Or, it could mark the share as failed but also mark the credential as invalid, prompting the tenant to re-connect their account.  This ties into credential management integration – we could enhance the `oauth_identities` handling to refresh tokens behind the scenes.  Also, better categorization of errors (maybe an error code field separate from human message) would help localize messages or decide when to stop retries.

* **Optimizing Delivery Timing:** Currently, scheduled\_at is a fixed time set by user or by retry logic.  In future, we could introduce intelligence: e.g., suggest the best time to post based on historical engagement (if data available), or avoid posting during certain hours.  This would be an AI or analytics-driven enhancement and would mostly affect the UI and scheduling logic (not the core queue mechanism, which can already handle arbitrary times).

* **User Collaboration and Approvals:** In larger organizations, one user might draft a post and another might approve it.  We might integrate a simple approval workflow: a post could be created in the queue in a “pending approval” state (not yet scheduled), and only upon approval does it get a `scheduled_at`.  This would mean adding an “approved” flag or status, and perhaps notifications to approvers.  While not in scope now, the data model is flexible enough to add a status or separate state for such a feature.

* **Testing and Sandbox Mode:** For safety, especially with social platforms, it’s useful to have a “sandbox” mode (to test without actually posting publicly).  Not all platforms have sandbox APIs, but we might simulate or allow posting to a test account.  For instance, during development, the adapters could be configured to hit a staging API or just log instead of posting.  We should ensure the code is structured to make such a mode easy (e.g. maybe a config flag `SocialShare.DryRun` that when true, the providers don’t actually call external APIs but pretend success).  This is mainly for development and QA, but prevents accidental spam to real accounts during testing.

Finally, as this system becomes a core part of Adept’s multi-channel messaging vision, we will keep an eye on aligning it with the **Messaging subsystem** (emails, SMS, push).  In the long run, there may be benefits to unifying the queue mechanics or providing a single interface for “send this content to X channel” where channels include social.  At present, they are separate for clarity, but lessons learned (like robust retry logic, metrics collection, etc.) will be shared between the systems.  We will also update documentation and developer guidelines accordingly, making the Social Share System a first-class part of Adept’s platform capabilities.

**Sources:**

* Adept Architecture – Messaging subsystem design for queue-based delivery (basis for queue & provider approach)
* Adept Comment Style Guide – guidelines followed in code examples
